{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea5277b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, math, random\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from rank_bm25 import BM25Okapi\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "def tokenize(text: str):\n",
    "    return re.findall(r\"[A-Za-z0-9]+\", str(text).lower())\n",
    "\n",
    "def dcg(rels):\n",
    "    return sum((2**rel - 1) / math.log2(i + 2) for i, rel in enumerate(rels))\n",
    "\n",
    "def ndcg_at_k(ranked_ids, rel_set, k=10):\n",
    "    rels = [1 if doc_id in rel_set else 0 for doc_id in ranked_ids[:k]]\n",
    "    ideal = sorted(rels, reverse=True)\n",
    "    denom = dcg(ideal)\n",
    "    return 0.0 if denom == 0 else dcg(rels) / denom\n",
    "\n",
    "def recall_at_k(ranked_ids, rel_set, k=100):\n",
    "    hit = sum(1 for doc_id in ranked_ids[:k] if doc_id in rel_set)\n",
    "    return hit / max(1, len(rel_set))\n",
    "\n",
    "def build_bm25(corpus_texts):\n",
    "    tokenized = [tokenize(t) for t in tqdm(corpus_texts, desc=\"Tokenizing corpus\")]\n",
    "    return BM25Okapi(tokenized), tokenized\n",
    "\n",
    "def bm25_search(bm25, query, topk=1000):\n",
    "    scores = bm25.get_scores(tokenize(query))\n",
    "    ranked = np.argsort(-scores)[:topk]\n",
    "    return ranked.tolist()\n",
    "\n",
    "def eval_intent_retrieval(df, text_col, intent_col, n_queries=200, min_rel=20, topk=1000):\n",
    "    \"\"\"\n",
    "    Query = random text\n",
    "    Relevant = same intent label (excluding itself)\n",
    "    \"\"\"\n",
    "    df = df.dropna(subset=[text_col, intent_col]).reset_index(drop=True)\n",
    "    corpus = df[text_col].astype(str).tolist()\n",
    "    intents = df[intent_col].astype(str).tolist()\n",
    "\n",
    "    from collections import defaultdict\n",
    "    intent_to_idx = defaultdict(list)\n",
    "    for i, lab in enumerate(intents):\n",
    "        intent_to_idx[lab].append(i)\n",
    "\n",
    "    eligible = [i for i, lab in enumerate(intents) if len(intent_to_idx[lab]) >= min_rel]\n",
    "    if len(eligible) == 0:\n",
    "        raise ValueError(\"No eligible queries: increase data or lower min_rel\")\n",
    "\n",
    "    chosen = random.sample(eligible, min(n_queries, len(eligible)))\n",
    "\n",
    "    bm25, _ = build_bm25(corpus)\n",
    "\n",
    "    ndcgs, recalls = [], []\n",
    "    for qi in tqdm(chosen, desc=\"Evaluating (intent retrieval)\"):\n",
    "        qtext = corpus[qi]\n",
    "        lab = intents[qi]\n",
    "        rel_set = set(intent_to_idx[lab]) - {qi}\n",
    "\n",
    "        ranked = bm25_search(bm25, qtext, topk=topk)\n",
    "        ndcgs.append(ndcg_at_k(ranked, rel_set, k=10))\n",
    "        recalls.append(recall_at_k(ranked, rel_set, k=100))\n",
    "\n",
    "    return float(np.mean(ndcgs)), float(np.mean(recalls)), len(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e8a0994",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "md = pd.read_parquet(PATH_MDCITE)\n",
    "print(\"MDCite columns:\", md.columns.tolist())\n",
    "print(\"Rows:\", len(md))\n",
    "\n",
    "def pick_col(cols, candidates):\n",
    "    for c in candidates:\n",
    "        if c in cols:\n",
    "            return c\n",
    "    return None\n",
    "\n",
    "cols = md.columns.tolist()\n",
    "TEXT_COL = pick_col(cols, [\"context\", \"text\", \"sentence\", \"citing_context\", \"citing_contexts\"])\n",
    "INTENT_COL = pick_col(cols, [\"intent\", \"intents\", \"label\"])\n",
    "FIELD_COL = pick_col(cols, [\"field\", \"category\", \"wos_field\"])\n",
    "\n",
    "print(\"Mapped:\", TEXT_COL, INTENT_COL, FIELD_COL)\n",
    "\n",
    "SAMPLE_N = min(200_000, len(md))\n",
    "if FIELD_COL:\n",
    "    stratified_sample_per_group = md.groupby(FIELD_COL, group_keys=False) \\\n",
    "                                    .apply(lambda x: x.sample(n=min(len(x), max(1000, SAMPLE_N // max(1, md[FIELD_COL].nunique()))),\n",
    "                                                              random_state=42), include_groups=False)\n",
    "    md_sample = stratified_sample_per_group.sample(n=min(SAMPLE_N, len(stratified_sample_per_group)), random_state=42) \\\n",
    "                                           .reset_index(drop=True)\n",
    "else:\n",
    "    md_sample = md.sample(n=SAMPLE_N, random_state=42).reset_index(drop=True)\n",
    "\n",
    "print(\"MDCite sample rows:\", len(md_sample))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c42718f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tarfile, json\n",
    "\n",
    "def load_scicite_from_tar(tar_path):\n",
    "    rows = []\n",
    "    with tarfile.open(tar_path, \"r:gz\") as tar:\n",
    "        members = [m for m in tar.getmembers() if m.isfile() and m.name.endswith((\".jsonl\", \".json\"))]\n",
    "        print(\"SciCite files:\", [m.name for m in members])\n",
    "\n",
    "        for m in members:\n",
    "            f = tar.extractfile(m)\n",
    "            if f is None:\n",
    "                continue\n",
    "            content = f.read().decode(\"utf-8\", errors=\"ignore\")\n",
    "\n",
    "            if m.name.endswith(\".jsonl\"):\n",
    "                for line in content.splitlines():\n",
    "                    line = line.strip()\n",
    "                    if not line:\n",
    "                        continue\n",
    "                    obj = json.loads(line)\n",
    "                    text = obj.get(\"string\") or obj.get(\"text\") or obj.get(\"sentence\")\n",
    "                    lab = obj.get(\"label\") or obj.get(\"intent\")\n",
    "                    if text is not None and lab is not None:\n",
    "                        rows.append({\"text\": text, \"intent\": lab})\n",
    "            else:\n",
    "                obj = json.loads(content)\n",
    "                if isinstance(obj, list):\n",
    "                    for it in obj:\n",
    "                        text = it.get(\"string\") or it.get(\"text\") or it.get(\"sentence\")\n",
    "                        lab = it.get(\"label\") or it.get(\"intent\")\n",
    "                        if text is not None and lab is not None:\n",
    "                            rows.append({\"text\": text, \"intent\": lab})\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "scidf = load_scicite_from_tar(PATH_SCICITE)\n",
    "print(\"SciCite rows:\", len(scidf))\n",
    "print(scidf.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19143cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "ndcg, rec, n = eval_intent_retrieval(\n",
    "    md_sample,\n",
    "    TEXT_COL,\n",
    "    INTENT_COL,\n",
    "    n_queries=200,\n",
    "    min_rel=30\n",
    ")\n",
    "results.append((\"MDCite (single)\", n, ndcg, rec))\n",
    "\n",
    "ndcg, rec, n = eval_intent_retrieval(\n",
    "    scidf,\n",
    "    \"text\",\n",
    "    \"intent\",\n",
    "    n_queries=200,\n",
    "    min_rel=30\n",
    ")\n",
    "results.append((\"SciCite\", n, ndcg, rec))\n",
    "\n",
    "results_df = pd.DataFrame(\n",
    "    results,\n",
    "    columns=[\"Dataset\", \"NumDocs\", \"BM25 nDCG@10\", \"BM25 Recall@100\"]\n",
    ")\n",
    "\n",
    "results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2136d70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_intent_retrieval_extended(\n",
    "    df, text_col, intent_col,\n",
    "    n_queries=200, min_rel=30, topk=2000\n",
    "):\n",
    "    df = df.dropna(subset=[text_col, intent_col]).reset_index(drop=True)\n",
    "    corpus = df[text_col].astype(str).tolist()\n",
    "    intents = df[intent_col].astype(str).tolist()\n",
    "\n",
    "    from collections import defaultdict\n",
    "    intent_to_idx = defaultdict(list)\n",
    "    for i, lab in enumerate(intents):\n",
    "        intent_to_idx[lab].append(i)\n",
    "\n",
    "    eligible = [i for i, lab in enumerate(intents)\n",
    "                if len(intent_to_idx[lab]) >= min_rel]\n",
    "    chosen = random.sample(eligible, min(n_queries, len(eligible)))\n",
    "\n",
    "    bm25, _ = build_bm25(corpus)\n",
    "\n",
    "    ndcgs, r100, r1000 = [], [], []\n",
    "    for qi in tqdm(chosen, desc=\"Eval intent retrieval\"):\n",
    "        qtext = corpus[qi]\n",
    "        lab = intents[qi]\n",
    "        rel_set = set(intent_to_idx[lab]) - {qi}\n",
    "\n",
    "        ranked = bm25_search(bm25, qtext, topk=topk)\n",
    "        ndcgs.append(ndcg_at_k(ranked, rel_set, k=10))\n",
    "        r100.append(recall_at_k(ranked, rel_set, k=100))\n",
    "        r1000.append(recall_at_k(ranked, rel_set, k=1000))\n",
    "\n",
    "    return (\n",
    "        float(np.mean(ndcgs)),\n",
    "        float(np.mean(r100)),\n",
    "        float(np.mean(r1000)),\n",
    "        len(df)\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39af7ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ndcg, r100, r1000, n = eval_intent_retrieval_extended(\n",
    "    md_sample, TEXT_COL, INTENT_COL\n",
    ")\n",
    "print(\"MDCite nDCG@10:\", ndcg)\n",
    "print(\"MDCite Recall@100:\", r100)\n",
    "print(\"MDCite Recall@1000:\", r1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ef91a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, math, random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from rank_bm25 import BM25Okapi\n",
    "from collections import defaultdict\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "def tokenize(text: str):\n",
    "    return re.findall(r\"[A-Za-z0-9]+\", str(text).lower())\n",
    "\n",
    "def dcg(rels):\n",
    "    return sum((2**rel - 1) / math.log2(i + 2) for i, rel in enumerate(rels))\n",
    "\n",
    "def ndcg_at_k(ranked_ids, rel_set, k=10):\n",
    "    rels = [1 if doc_id in rel_set else 0 for doc_id in ranked_ids[:k]]\n",
    "    ideal = sorted(rels, reverse=True)\n",
    "    denom = dcg(ideal)\n",
    "    return 0.0 if denom == 0 else dcg(rels) / denom\n",
    "\n",
    "def recall_at_k(ranked_ids, rel_set, k=100):\n",
    "    hit = sum(1 for doc_id in ranked_ids[:k] if doc_id in rel_set)\n",
    "    return hit / max(1, len(rel_set))\n",
    "\n",
    "def build_bm25(corpus_texts):\n",
    "    tokenized = [tokenize(t) for t in tqdm(corpus_texts, desc=\"Tokenizing corpus\")]\n",
    "    bm25 = BM25Okapi(tokenized)\n",
    "    return bm25\n",
    "\n",
    "def bm25_search(bm25, query, topk=2000):\n",
    "    scores = bm25.get_scores(tokenize(query))\n",
    "    ranked = np.argsort(-scores)[:topk]\n",
    "    return ranked.tolist()\n",
    "def sample_queries_for_intent_task(df, text_col, intent_col, n_queries=200, min_rel=5):\n",
    "    df = df.dropna(subset=[text_col, intent_col]).reset_index(drop=True)\n",
    "    intents = df[intent_col].astype(str).tolist()\n",
    "\n",
    "    intent_to_idx = defaultdict(list)\n",
    "    for i, lab in enumerate(intents):\n",
    "        intent_to_idx[lab].append(i)\n",
    "\n",
    "    eligible = [i for i, lab in enumerate(intents) if len(intent_to_idx[lab]) >= (min_rel + 1)]\n",
    "    if not eligible:\n",
    "        raise ValueError(\"No eligible queries. Lower min_rel or check labels.\")\n",
    "\n",
    "    chosen = random.sample(eligible, min(n_queries, len(eligible)))\n",
    "    return df, intent_to_idx, chosen\n",
    "def recall_at_k_curve_bm25(\n",
    "    df, text_col, intent_col,\n",
    "    k_values=(10, 50, 100, 200, 500, 1000),\n",
    "    n_queries=200,\n",
    "    min_rel=5,\n",
    "    topk=2000\n",
    "):\n",
    "    df, intent_to_idx, chosen = sample_queries_for_intent_task(\n",
    "        df, text_col, intent_col, n_queries=n_queries, min_rel=min_rel\n",
    "    )\n",
    "\n",
    "    corpus = df[text_col].astype(str).tolist()\n",
    "    intents = df[intent_col].astype(str).tolist()\n",
    "\n",
    "    bm25 = build_bm25(corpus)\n",
    "\n",
    "    k_values = list(k_values)\n",
    "    recalls = {k: [] for k in k_values}\n",
    "\n",
    "    for qi in tqdm(chosen, desc=\"Evaluating Recall@k curve\"):\n",
    "        qtext = corpus[qi]\n",
    "        lab = intents[qi]\n",
    "        rel_set = set(intent_to_idx[lab]) - {qi}\n",
    "\n",
    "        ranked = bm25_search(bm25, qtext, topk=topk)\n",
    "\n",
    "        for k in k_values:\n",
    "            recalls[k].append(recall_at_k(ranked, rel_set, k=k))\n",
    "\n",
    "    curve = {f\"Recall@{k}\": float(np.mean(vals)) for k, vals in recalls.items()}\n",
    "    curve[\"NumQueries\"] = len(chosen)\n",
    "    curve[\"NumDocs\"] = len(df)\n",
    "    return curve\n",
    "curve = recall_at_k_curve_bm25(\n",
    "    md_sample, TEXT_COL, INTENT_COL,\n",
    "    k_values=(10, 50, 100, 200, 500, 1000),\n",
    "    n_queries=200,\n",
    "    min_rel=30,      \n",
    "    topk=2000\n",
    ")\n",
    "\n",
    "pd.DataFrame([curve])\n",
    "def intent_wise_metrics_on_global_corpus(\n",
    "    df, text_col, intent_col,\n",
    "    intents_list=None,\n",
    "    max_queries_per_intent=100,\n",
    "    min_rel=5,\n",
    "    topk=2000\n",
    "):\n",
    "    df = df.dropna(subset=[text_col, intent_col]).reset_index(drop=True)\n",
    "    corpus = df[text_col].astype(str).tolist()\n",
    "    intents = df[intent_col].astype(str).tolist()\n",
    "\n",
    "    intent_to_idx = defaultdict(list)\n",
    "    for i, lab in enumerate(intents):\n",
    "        intent_to_idx[lab].append(i)\n",
    "\n",
    "    if intents_list is None:\n",
    "        intents_list = sorted(intent_to_idx.keys())\n",
    "\n",
    "    bm25 = build_bm25(corpus)\n",
    "\n",
    "    rows = []\n",
    "    for lab in intents_list:\n",
    "        idxs = intent_to_idx.get(lab, [])\n",
    "        if len(idxs) < (min_rel + 1):\n",
    "            rows.append({\n",
    "                \"Intent\": lab,\n",
    "                \"NumDocs\": len(idxs),\n",
    "                \"nDCG@10\": None,\n",
    "                \"Recall@100\": None,\n",
    "                \"Recall@1000\": None,\n",
    "                \"NumQueries\": 0\n",
    "            })\n",
    "            continue\n",
    "\n",
    "        n_q = min(max_queries_per_intent, len(idxs))\n",
    "        chosen = random.sample(idxs, n_q)\n",
    "\n",
    "        ndcgs, r100, r1000 = [], [], []\n",
    "        for qi in tqdm(chosen, desc=f\"Intent={lab}\", leave=False):\n",
    "            qtext = corpus[qi]\n",
    "            rel_set = set(idxs) - {qi}\n",
    "\n",
    "            ranked = bm25_search(bm25, qtext, topk=topk)\n",
    "\n",
    "            ndcgs.append(ndcg_at_k(ranked, rel_set, k=10))\n",
    "            r100.append(recall_at_k(ranked, rel_set, k=100))\n",
    "            r1000.append(recall_at_k(ranked, rel_set, k=1000))\n",
    "\n",
    "        rows.append({\n",
    "            \"Intent\": lab,\n",
    "            \"NumDocs\": len(idxs),\n",
    "            \"nDCG@10\": float(np.mean(ndcgs)),\n",
    "            \"Recall@100\": float(np.mean(r100)),\n",
    "            \"Recall@1000\": float(np.mean(r1000)),\n",
    "            \"NumQueries\": len(chosen)\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(rows).sort_values(\"NumDocs\", ascending=False).reset_index(drop=True)\n",
    "intent_table = intent_wise_metrics_on_global_corpus(\n",
    "    md_sample,\n",
    "    TEXT_COL,\n",
    "    INTENT_COL,\n",
    "    intents_list=None,             \n",
    "    max_queries_per_intent=100,\n",
    "    min_rel=5,\n",
    "    topk=2000\n",
    ")\n",
    "\n",
    "intent_table\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "curve = recall_at_k_curve_bm25(\n",
    "    md_sample, TEXT_COL, INTENT_COL,\n",
    "    k_values=(10, 50, 100, 200, 500, 1000),\n",
    "    n_queries=200,\n",
    "    min_rel=30,\n",
    "    topk=2000\n",
    ")\n",
    "\n",
    "ks = [10, 50, 100, 200, 500, 1000]\n",
    "vals = [curve[f\"Recall@{k}\"] for k in ks]\n",
    "\n",
    "plt.figure(figsize=(6.5, 4))\n",
    "plt.plot(ks, vals, marker=\"o\")\n",
    "plt.xscale(\"log\")\n",
    "plt.xlabel(\"k (log scale)\")\n",
    "plt.ylabel(\"Recall@k\")\n",
    "plt.title(\"BM25 Recall@k Curve (Intent Retrieval)\")\n",
    "plt.grid(True, linestyle=\"--\", alpha=0.5)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
